{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning datasets and combine all the JSON files together\n",
    "\n",
    "In this file we will combine all the datasets together in a single dictionary\n",
    "\n",
    "In this simulation there are six different datasts: \n",
    "'hlisa_traces', 'gremlins', 'za_proxy', 'survey_desktop', 'random_mouse_bot', 'random_mouse_with_sleep_bot'\n",
    "\n",
    "By the end we will have \"pos_dict\" for all the datasets and each of them contains the 'time', 'x','y', 'event' and the 'dir' which is the direction of the mouse. \n",
    "\n",
    "Please write your Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlisa_traces\n",
      "gremlins\n",
      "za_proxy\n",
      "survey_desktop\n",
      "random_mouse_bot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "#cleaning datasets and combine all the JSON files together\n",
    "\n",
    "# Define the list of directories to check. These are the directories which contain your data files.\n",
    "PATH= 'samples'\n",
    "directories = ['hlisa_traces', 'gremlins', 'za_proxy', 'survey_desktop', 'random_mouse_bot']\n",
    "\n",
    "# Define the list of events to be searched for in the data files.\n",
    "_docEvents = 'mousedown mouseup mousemove mouseover mouseout mousewheel wheel'\n",
    "_docEvents += ' touchstart touchend touchmove deviceorientation keydown keyup keypress'\n",
    "_docEvents += ' click dblclick scroll change select submit reset contextmenu cut copy paste'\n",
    "_winEvents = 'load unload beforeunload blur focus resize error abort online offline'\n",
    "_winEvents += ' storage popstate hashchange pagehide pageshow message beforeprint afterprint'\n",
    "\n",
    "\n",
    "events = _docEvents.split() + _winEvents.split()\n",
    "\n",
    "num_events=len(events)\n",
    "\n",
    "df_names=directories\n",
    "# Initialize an empty dictionary to hold data. One list per directory.\n",
    "data = {dir: [] for dir in directories}\n",
    "\n",
    "# Function to convert string to int (used for timestamps)\n",
    "def str2int(s):\n",
    "    return int(s.replace(',', ''))\n",
    "\n",
    "# Iterate over each directory\n",
    "for directory in directories:\n",
    "    print(directory)\n",
    "    # Get the list of files in the directory\n",
    "    files = os.listdir(PATH+directory)\n",
    "\n",
    "    # Iterate over each file\n",
    "    for file in files:\n",
    "        # Make sure we only read .json files\n",
    "        if file.endswith('.json'):\n",
    "            # Construct the full file path by joining the directory and file name\n",
    "            filepath = PATH+os.path.join(directory, file)\n",
    "            \n",
    "            # Open the file\n",
    "            with open(filepath, 'r') as f:\n",
    "                # Load the json data\n",
    "                json_data = json.load(f)\n",
    "                \n",
    "                # Append the data to our data list for the current directory\n",
    "                data[directory].append(json_data)\n",
    "\n",
    "# Initialize an empty dictionary to hold the pandas dataframes for each directory\n",
    "df_dict_init = {}\n",
    "\n",
    "# Create an empty DataFrame for each name\n",
    "for name in df_names:\n",
    "    df_dict_init[name] = pd.DataFrame() \n",
    "\n",
    "# Create a dictionary for quick event name to index conversion\n",
    "events_index = {event: index for index, event in enumerate(events)}\n",
    "for name in df_names:\n",
    "    all_matches = []  # List to collect all match data\n",
    "\n",
    "    for i in range(len(data[name])):\n",
    "        trace = data[name][i]['trace'] \n",
    "\n",
    "        for j in range(len(trace)):\n",
    "            # Convert timestamp to seconds and then to datetime object\n",
    "            timestamp_in_seconds = str2int(trace[j]['timestamp'])/1000\n",
    "            dt_object = datetime.datetime.fromtimestamp(timestamp_in_seconds)\n",
    "\n",
    "            # Convert event name to index\n",
    "            index = events_index.get(trace[j]['event_name'], -1)\n",
    "            all_matches.append((j, dt_object,trace[j]['position']['x'], trace[j]['position']['y'], index))\n",
    "\n",
    "    # Convert all matches into a DataFrame outside of loop\n",
    "    df_dict_init[name] = pd.DataFrame(all_matches, columns=['userId', 'timestamp', 'x', 'y', 'eventName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlisa_traces\n",
      "gremlins\n",
      "za_proxy\n",
      "survey_desktop\n",
      "random_mouse_bot\n",
      "hlisa_traces\n",
      "921721\n",
      "gremlins\n",
      "386281\n",
      "za_proxy\n",
      "90992\n",
      "survey_desktop\n",
      "1589067\n",
      "random_mouse_bot\n",
      "150507\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_dict=df_dict_init\n",
    "\n",
    "def replace_zero_with_next_non_zero(arr):\n",
    "    next_non_zero = None\n",
    "    for i in reversed(range(len(arr))):\n",
    "        if arr[i] != 0 and arr[i] != '0':\n",
    "            next_non_zero = arr[i]\n",
    "        elif next_non_zero is not None:\n",
    "            arr[i] = next_non_zero\n",
    "    return arr\n",
    "    \n",
    "num_bins = 3\n",
    "\n",
    "# Iterate over each DataFrame\n",
    "for df_name in df_names:\n",
    "    print(df_name)\n",
    "    df = df_dict[df_name]\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    df_x_temp = df['x'].to_numpy()\n",
    "    df_y_temp = df['y'].to_numpy()\n",
    "\n",
    "    # Apply the replacement function to the numpy arrays\n",
    "    df_x_temp = replace_zero_with_next_non_zero(df_x_temp)\n",
    "    df_y_temp = replace_zero_with_next_non_zero(df_y_temp)\n",
    "\n",
    "    # Assign the numpy arrays back to the DataFrame\n",
    "    df['x'] = df_x_temp\n",
    "    df['y'] = df_y_temp\n",
    "\n",
    "    # 1. Sort the dataframe by timestamp\n",
    "    \n",
    "\n",
    "  \n",
    "    # Save the modified DataFrame back into the dictionary\n",
    "    df['time_diff'] = df['timestamp'].diff().dt.total_seconds() * 1000\n",
    "    df_dict[df_name] = df\n",
    "\n",
    "    # 2. Compute differences between successive timestamps\n",
    "    \n",
    "\n",
    "# Compute the quantile-based bins\n",
    "df=df_dict['survey_desktop']\n",
    "thresholds = pd.qcut(df['time_diff'], q=num_bins, duplicates='drop').unique().sort_values()\n",
    "bin_edges = [interval.right for interval in thresholds[:-1]]\n",
    "bin_edges=[-1]+bin_edges+[5000000000]\n",
    "labels = list(range(len(bin_edges) - 1))\n",
    "\n",
    "# Prepare dictionaries to hold the replicated rows\n",
    "X_dict = {}\n",
    "Y_dict = {}\n",
    "T_dict = {}\n",
    "Event_dict={}\n",
    "\n",
    "# Iterate over each DataFrame again\n",
    "for name in df_names:\n",
    "    print(name)\n",
    "    X_dict[name] = []\n",
    "    Y_dict[name] = []\n",
    "    T_dict[name] = []\n",
    "    Event_dict[name] = []\n",
    "\n",
    "    df=df_dict[name]\n",
    "\n",
    "    # Assign bins to time differences\n",
    "    df['time_diff_bins'] = pd.cut(df['time_diff'], bins=bin_edges, labels=labels)\n",
    "\n",
    "    # Iterate over DataFrame rows\n",
    "    for idx, row in df.iterrows():\n",
    "        # Determine number of times to replicate the row\n",
    "        n_rep = row['time_diff_bins']\n",
    "\n",
    "        # If n_rep is not nan, replicate the row\n",
    "        if not np.isnan(n_rep):\n",
    "            n_rep = int(n_rep) + 1\n",
    "                \n",
    "            x = row['x'] if type(row['x']) != str else str2int(row['x'])\n",
    "            y = row['y'] if type(row['y']) != str else str2int(row['y'])\n",
    "\n",
    "            # Replicate and extend the lists\n",
    "            X_dict[name].extend([x] * n_rep)\n",
    "            Y_dict[name].extend([y] * n_rep)\n",
    "            T_dict[name].extend([row['timestamp']] * n_rep)\n",
    "            Event_dict[name].extend([row['eventName']] * n_rep)\n",
    "\n",
    "\n",
    "    print(len(X_dict[name]))\n",
    "\n",
    "# Combine the dictionaries into a single dictionary\n",
    "pos_dict= {'x': X_dict, 'y': Y_dict, 't': T_dict, 'event': Event_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlisa_traces\n",
      "gremlins\n",
      "za_proxy\n",
      "survey_desktop\n",
      "random_mouse_bot\n"
     ]
    }
   ],
   "source": [
    "pos_dict['dir']={}\n",
    "pos_dict['time']={}\n",
    "import numpy as np\n",
    "lim = 40\n",
    "bins = 2\n",
    "num_events=len(events)\n",
    "\n",
    "for name in df_names:\n",
    "    print(name)\n",
    "    \n",
    "    length = len(pos_dict['x'][name])\n",
    "    \n",
    "    # Pre-allocate NumPy arrays\n",
    "    pos_dict['dir'][name] = np.zeros(length)\n",
    "    pos_dict['time'][name]=[]\n",
    "    \n",
    "    # Calculate time differences efficiently\n",
    "    for i in range(len(pos_dict['x'][name])):\n",
    "        pos_dict['time'][name].append(pos_dict['t'][name][i]-pos_dict['t'][name][0])\n",
    "    \n",
    "    # Calculate differences for x and y\n",
    "    x_diff = np.diff(pos_dict['x'][name], prepend=pos_dict['x'][name][0])\n",
    "    y_diff = np.diff(pos_dict['y'][name], prepend=pos_dict['y'][name][0])\n",
    "    \n",
    "    # Bin x and y directions\n",
    "    x_dir_binned = np.clip(np.floor(x_diff / lim), -bins, bins) + bins\n",
    "    y_dir_binned = np.clip(np.floor(y_diff / lim), -bins, bins) + bins\n",
    "    \n",
    "    # Update dir field\n",
    "    pos_dict['dir'][name] = pos_dict['event'][name] + x_dir_binned * num_events + y_dir_binned * num_events**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pos_dict using pickle to be used in classifiers\n",
    "import pickle\n",
    "with open('data/pos_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(pos_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
